{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ Hi Everyone, Welcome to the GenAI Journey! ü§ñ‚ú®\n",
        "\n",
        "üåü As this is our very first practical in this series, we‚Äôll start with the most important step\n",
        "\n",
        "üìå Data Cleaning (also called Text Preprocessing for NLP / ML / GenAI)\n",
        "\n",
        "This process transforms messy, real-world text into clean, structured input that models can understand and learn from.\n",
        "This file contains reusable and modular functions for cleaning raw text.\n",
        "It's designed for use in NLP tasks, chatbots, sentiment analysis, and LLM-based systems.\n",
        "Each step in this script is explained with clear comments and practical use cases."
      ],
      "metadata": {
        "id": "HnOZU0cQP7XU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Required Libraries and Dataset**"
      ],
      "metadata": {
        "id": "YkOb_-C4QIGt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X17SfNuXP21L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"https://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv\")"
      ],
      "metadata": {
        "id": "nM4y6VoZQU4q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U51DeSLuQcEB",
        "outputId": "6de83a64-9a02-49d5-b3a3-a6fd470cdffd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "44501  \"Imaginary Heroes\" is a 2004 film starring Sig...  positive\n",
              "16945  So don't even think about renting this from th...  negative\n",
              "8408   \"The Next Karate Kid\" is a thoroughly predicta...  negative\n",
              "34144  I expected a bad movie, and got a bad movie. B...  negative\n",
              "9360   Another hand-held horror means another divisiv...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34b71603-5665-4a3f-ba55-b59f99a7efbc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44501</th>\n",
              "      <td>\"Imaginary Heroes\" is a 2004 film starring Sig...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16945</th>\n",
              "      <td>So don't even think about renting this from th...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8408</th>\n",
              "      <td>\"The Next Karate Kid\" is a thoroughly predicta...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34144</th>\n",
              "      <td>I expected a bad movie, and got a bad movie. B...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9360</th>\n",
              "      <td>Another hand-held horror means another divisiv...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34b71603-5665-4a3f-ba55-b59f99a7efbc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34b71603-5665-4a3f-ba55-b59f99a7efbc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34b71603-5665-4a3f-ba55-b59f99a7efbc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6898b7f5-cc62-43c9-8449-d59b42d4799c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6898b7f5-cc62-43c9-8449-d59b42d4799c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6898b7f5-cc62-43c9-8449-d59b42d4799c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"So don't even think about renting this from the shops, because this is one hell of a bad movie. You'd think that JJ Abrahams had written this movie. Basically, a rat is flushed down the toilet and somehow has to get back out. Fans of the completely terrible \\\"Shrek\\\" might enjoy, but \\\"Wallace & Gromit\\\" fans will probably turn away in disgust. Also, why didn't they do it in plasticine or clay? I mean, CGI animation?? For an AARDMAN movie??!! Obviously, Aardman lazed around while they let Dreamworks do the whole thing. Wrong, wrong, WRONG!!! Nearly every single character is awful, apart from that freaky frog guy, who is just right for a movie villain. But everything else about the movie is DULL, DULL, DULL!!! I almost fell asleep with boredom watching this movie. No, wait, actually, I DID fall asleep with boredom watching this movie. It's just terrible. But thankfully, it's not as bad as \\\"Shrek.\\\"\",\n          \"Another hand-held horror means another divisive movie that fans should still seek out and make up their own minds about.<br /><br />Imagine a cross between The Blair Witch Project and The Grudge and you're close to the overall content of this movie. It's another videotaped horror but this time most of it is edited together in readiness for a video doc that was never completed by a supernatural investigator who disappeared.<br /><br />I certainly had a feeling of dread while watching this movie (does anyone do dreadful better than our Asian friends?) but the creepy moments, the genuinely creepy moments, were sadly a bit fewer and farther between than I had hoped. I also felt that I was two or three steps ahead of the investigator when apparent \\\"revelations\\\" appeared throughout so I certainly can't recommend this as highly as [*Rec].<br /><br />Having said that, it would be remiss of me not to highly recommend any film that goes on at length about ectoplasmic worms, contains at least two subtly spooky ghost moments and made sure that I had to put the lights back on for a while when the sun went down.<br /><br />Check it out if you have been enjoying some of the other hand-held genre releases of late. And the finale is a hair-raising doozy.<br /><br />See this if you like: The Last Broadcast, Pulse, Angel Heart.\",\n          \"\\\"The Next Karate Kid\\\" is a thoroughly predictable movie, just like its predecessors. Its predictability often results in a feeling of impatience on the viewer's part, who often wishes the story could move a little faster. Despite its lulls and its extreme familiarity, however, this fourth entry in the series is painless, almost exclusively because of the presence of Morita. He doesn't seem tired of his role, and he does inject some life and humor into the film, becoming the best reason for you to see it. Not awful, but nothing much, either.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Individual Cleaning Functions (Text Pre-Processing)\n",
        "Each function handles a specific part of the text cleaning pipeline."
      ],
      "metadata": {
        "id": "RqJr_SVuQjPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Lowercasing\n",
        "\n",
        "üîπ Convert all characters to lowercase for uniformity"
      ],
      "metadata": {
        "id": "wz0bTOKfQwju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'] = data['review'].str.lower()"
      ],
      "metadata": {
        "id": "Tc25196gQdfL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"review\"][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Aa90yrbUQsPa",
        "outputId": "b9a741cb-4fb7-463b-ea04-ce44ae51cca1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Remove HTMLs Tags\n",
        "\n",
        "üîπRemove HTML tags from text to ensures data is fully readable and clean for NLP or GenAI models"
      ],
      "metadata": {
        "id": "mRRWVDEQQ_dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them\"\n"
      ],
      "metadata": {
        "id": "H62DrwJ5Q8iV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## To find pattern from data we use Regular Expression (Text Data)\n",
        "import re\n",
        "def Remove_html_tags(text):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    return pattern.sub(\"\",text)"
      ],
      "metadata": {
        "id": "-hQHTp0dRHhh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Remove_html_tags(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "RV7uvqg7RKh4",
        "outputId": "78aa91ac-7a4d-4196-c019-f1ce78983f47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'] = data['review'].apply(Remove_html_tags)"
      ],
      "metadata": {
        "id": "kSkx7IDzRNOw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Remove Urls\n",
        "\n",
        "üîπRemove URLs from Text e.g: (http:.www.//example.com)"
      ],
      "metadata": {
        "id": "PHywsajyRYJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Remove_url(text):\n",
        "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return pattern.sub(\"\",text)"
      ],
      "metadata": {
        "id": "ra86dlXLRkWO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = 'Visit on Website https://www.org/'"
      ],
      "metadata": {
        "id": "cHCYOdPoRq34"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Remove_url(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dpQMpQ95RtYY",
        "outputId": "8af89385-d4f8-44f3-e292-9665715a6710"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Visit on Website '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'] = data['review'].apply(Remove_url)"
      ],
      "metadata": {
        "id": "ZhKLFpG9RvGV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Remove punctuation and special characters\n",
        "\n",
        "üîπ Attribute Punctuations"
      ],
      "metadata": {
        "id": "oH1Uy4MORx2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "PK9X_K2URxM1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LEQej0i0R5ZJ",
        "outputId": "b684d10b-7e18-4d97-d899-b436c3f12f29"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exclude = string.punctuation"
      ],
      "metadata": {
        "id": "d0KKdK3nR9Sv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Remove_punct(text):\n",
        "    for char in exclude:\n",
        "        text = text.replace(char,\"\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "EjiVRYV5SA0M"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'] = data['review'].apply(Remove_punct)"
      ],
      "metadata": {
        "id": "ecdq0hgQSGeF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "V03Y4LcDSKXv",
        "outputId": "bfb3d33c-efc6-42b1-a00c-b3828ed0032b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a lighthearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to lovethis was the most id laughed at one of woodys comedies in years dare i say a decade while ive never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young womanthis may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman a great comedy to go see with friends'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Slangs\n",
        "\n",
        "üîπ(Short Words / Abbrivation)\n"
      ],
      "metadata": {
        "id": "Gn6Dcf9nSYJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_word= {\"AFK\": \"Away From Keyboard\",\n",
        "\"ASAP\":\"As Soon As Possible\",\n",
        "\"BTW\":\"By The Way\",\n",
        "\"B4\":\"Before\",\n",
        "\"LAMO\":\"Laugh My A.. Off\",\n",
        "\"FYI\":\"For your information\"}"
      ],
      "metadata": {
        "id": "aJfuBJXDSPqW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"FYI this is not true\"\n",
        "text2 = \"LAMO the class was so funny\"\n",
        "text3 = \"i want report ASAP\""
      ],
      "metadata": {
        "id": "_qqQMVijSnw9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_conversion(text):\n",
        "  new_text=[]\n",
        "  for w in text.split():\n",
        "      if w.upper() in chat_word:\n",
        "        new_text.append(chat_word[w.upper()])\n",
        "      else:\n",
        "        new_text.append(w)\n",
        "  return \" \".join(new_text)"
      ],
      "metadata": {
        "id": "4lvXAvRBSsP6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_conversion(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xnkR3glhSuzN",
        "outputId": "b393c7cf-277f-4818-e29b-81849d0c8d46"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For your information this is not true'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. spelling Correction"
      ],
      "metadata": {
        "id": "bmyCd1yTSy58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing spelling correct module\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "lC1z871vSw-r"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Writing the text for Correction\n",
        "text = 'plese downlod my notbok'"
      ],
      "metadata": {
        "id": "HshFYWs2S_Q4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TextBlob(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ0X2hryTIfk",
        "outputId": "66bedaac-3540-49b6-ef19-f7f2a98dadc2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"plese download my notbook\")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating  a callable variable\n",
        "txtblob = TextBlob(text)"
      ],
      "metadata": {
        "id": "i83AxNdeTULP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txtblob.correct().string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TWLqWKg9TYFO",
        "outputId": "b4723dcd-df31-4737-beb9-46e10707e5fe"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'please download my notebook'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Remove common stopwords from Text"
      ],
      "metadata": {
        "id": "gKVBkGJlTb-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "AcUwNjIUTkdL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyDUg4Z4Tpjt",
        "outputId": "e4fcf7f9-0e6b-49e7-db44-73d00272d5d4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words(\"english\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKE5quypTwb_",
        "outputId": "5111d07e-4a55-472f-cdb9-15b39cf6a55f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text5 = \"I'am Asmit and we all are learning GenAi and Nlp which is Important\""
      ],
      "metadata": {
        "id": "TpHn2bViT-yY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    new_text=[]\n",
        "    for word in text.split():\n",
        "        if word in stopwords.words(\"english\"):\n",
        "         new_text.append(\"\")\n",
        "        else:\n",
        "            new_text.append(word)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "id": "ZNE007A7UBHl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_stopwords(text5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MQ-Tr96nUFeT",
        "outputId": "b3c7264e-2856-4b93-a22a-59262167fbe3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'am Asmit     learning GenAi  Nlp   Important\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Remove emojis from text to avoid noise in analysis & Convert emojis to their textual description"
      ],
      "metadata": {
        "id": "ivfKT5eoUMQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7YDr_OIUOpQ",
        "outputId": "e7457701-b1fe-4ca1-e31f-3f5ebd337464"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m317.4/590.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji"
      ],
      "metadata": {
        "id": "mpaLOdkqUIab"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_text = \"This is a üòÉ sample text with some stopwords like a and the üöÄ\""
      ],
      "metadata": {
        "id": "iys3DF0BUOUV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This is Manual way to Remove Emojis\n",
        "def remove_emojis(text):\n",
        "    emoji_pattern = re.compile(\"[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)"
      ],
      "metadata": {
        "id": "eadFetbMUdy3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_emojis(original_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GhywjsmTUuFf",
        "outputId": "772f9bb3-5e95-429c-b03e-fc9f5bedc032"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a  sample text with some stopwords like a and the '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert emojis to their textual description\n",
        "def demojize_emojis(text):\n",
        "    return emoji.demojize(text)"
      ],
      "metadata": {
        "id": "o7nbbeK-U0le"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demojize_emojis(original_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-Ph1o55pU6xF",
        "outputId": "775326d5-42fb-4feb-b5fd-a7f8824fb083"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a :grinning_face_with_big_eyes: sample text with some stopwords like a and the :rocket:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Tokenization"
      ],
      "metadata": {
        "id": "Q3L3sSQiVQ9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "id": "3XDTw77AU8w3"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt_tab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hcEhiR3VU5B",
        "outputId": "82a559e2-b95c-46bb-8fd1-21a2f2a3e7d9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"i am asmit working as a data Analyst Intern. i work in analytical team\""
      ],
      "metadata": {
        "id": "xend0heuX44Y"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92XVkSDsYFeQ",
        "outputId": "4b0cf662-9cfd-4bdc-c97c-e63d66bb3b3a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'am',\n",
              " 'asmit',\n",
              " 'working',\n",
              " 'as',\n",
              " 'a',\n",
              " 'data',\n",
              " 'Analyst',\n",
              " 'Intern.',\n",
              " 'i',\n",
              " 'work',\n",
              " 'in',\n",
              " 'analytical',\n",
              " 'team']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split is a simplest way\n",
        "# but lets say split is not working in that case you can with regular expression"
      ],
      "metadata": {
        "id": "iT8Vl4ORXzEm"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_text = \"i am going to delhi today evening\""
      ],
      "metadata": {
        "id": "Jk8eufzqVXn_"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(my_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnZU1V_QVbzZ",
        "outputId": "e99053d1-de0d-40ad-8bba-8f4e6e31ff03"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'going', 'to', 'delhi', 'today', 'evening']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## A corpus is essentially a database of language data, containing a vast amount of text and/or speech\n",
        "my_corpus = \"\"\"Generative artificial intelligence (generative AI, genAI, GenAI, GAI or GenAI[1]) is artificial intelligence capable of generating text, images or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\n",
        "Improvements in transformer-based deep neural networks enabled an AI boom of generative AI systems in the early 2020s. These include large language model (LLM) chatbots such as ChatGPT, Copilot, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.[7][8][9] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\"\"\""
      ],
      "metadata": {
        "id": "i8kAPnimVzAW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(my_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lefuoi8yV9zv",
        "outputId": "d518cc9e-ce49-49a1-be1e-bb695636faa4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Generative artificial intelligence (generative AI, genAI, GenAI, GAI or GenAI[1]) is artificial intelligence capable of generating text, images or other data using generative models,[2] often in response to prompts.',\n",
              " '[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.',\n",
              " '[5][6]\\nImprovements in transformer-based deep neural networks enabled an AI boom of generative AI systems in the early 2020s.',\n",
              " 'These include large language model (LLM) chatbots such as ChatGPT, Copilot, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.[7][8][9] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can do it by using nltk and even with spacy\n",
        "- split\n",
        "- regular expression(simple google)\n",
        "- nltk"
      ],
      "metadata": {
        "id": "UCJwFbqJWKc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer.\n",
        "import spacy"
      ],
      "metadata": {
        "id": "jbVBeXFBWTEf"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "O6X01OeCWXEA"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text):\n",
        "    # Process the text with the spacy model\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Extract tokens from the processed document\n",
        "    tokens = [token.text for token in doc]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "igBudxtjWZyo"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=tokenize_text(my_corpus)"
      ],
      "metadata": {
        "id": "BlDah7YiW36S"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokens:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fKmfeTMW5Sv",
        "outputId": "b518e63e-4fbe-427e-c651-be1e1362a33d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative\n",
            "artificial\n",
            "intelligence\n",
            "(\n",
            "generative\n",
            "AI\n",
            ",\n",
            "genAI\n",
            ",\n",
            "GenAI\n",
            ",\n",
            "GAI\n",
            "or\n",
            "GenAI[1\n",
            "]\n",
            ")\n",
            "is\n",
            "artificial\n",
            "intelligence\n",
            "capable\n",
            "of\n",
            "generating\n",
            "text\n",
            ",\n",
            "images\n",
            "or\n",
            "other\n",
            "data\n",
            "using\n",
            "generative\n",
            "models,[2\n",
            "]\n",
            "often\n",
            "in\n",
            "response\n",
            "to\n",
            "prompts.[3][4\n",
            "]\n",
            "Generative\n",
            "AI\n",
            "models\n",
            "learn\n",
            "the\n",
            "patterns\n",
            "and\n",
            "structure\n",
            "of\n",
            "their\n",
            "input\n",
            "training\n",
            "data\n",
            "and\n",
            "then\n",
            "generate\n",
            "new\n",
            "data\n",
            "that\n",
            "has\n",
            "similar\n",
            "characteristics.[5][6\n",
            "]\n",
            "\n",
            "\n",
            "Improvements\n",
            "in\n",
            "transformer\n",
            "-\n",
            "based\n",
            "deep\n",
            "neural\n",
            "networks\n",
            "enabled\n",
            "an\n",
            "AI\n",
            "boom\n",
            "of\n",
            "generative\n",
            "AI\n",
            "systems\n",
            "in\n",
            "the\n",
            "early\n",
            "2020s\n",
            ".\n",
            "These\n",
            "include\n",
            "large\n",
            "language\n",
            "model\n",
            "(\n",
            "LLM\n",
            ")\n",
            "chatbots\n",
            "such\n",
            "as\n",
            "ChatGPT\n",
            ",\n",
            "Copilot\n",
            ",\n",
            "Bard\n",
            ",\n",
            "and\n",
            "LLaMA\n",
            ",\n",
            "and\n",
            "text\n",
            "-\n",
            "to\n",
            "-\n",
            "image\n",
            "artificial\n",
            "intelligence\n",
            "art\n",
            "systems\n",
            "such\n",
            "as\n",
            "Stable\n",
            "Diffusion\n",
            ",\n",
            "Midjourney\n",
            ",\n",
            "and\n",
            "DALL\n",
            "-\n",
            "E.[7][8][9\n",
            "]\n",
            "Companies\n",
            "such\n",
            "as\n",
            "OpenAI\n",
            ",\n",
            "Anthropic\n",
            ",\n",
            "Microsoft\n",
            ",\n",
            "Google\n",
            ",\n",
            "and\n",
            "Baidu\n",
            "as\n",
            "well\n",
            "as\n",
            "numerous\n",
            "smaller\n",
            "firms\n",
            "have\n",
            "developed\n",
            "generative\n",
            "AI\n",
            "models\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "text = \"Spacy is a powerful natural language processing library.\"\n",
        "tokens = tokenize_text(text)\n",
        "\n",
        "print(f\"Original text: {text}\")\n",
        "print(f\"Tokens: {tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOSVtc6jYUUB",
        "outputId": "4c34028b-a175-40cd-d802-5937ec9d5cf5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: Spacy is a powerful natural language processing library.\n",
            "Tokens: ['Spacy', 'is', 'a', 'powerful', 'natural', 'language', 'processing', 'library', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Stemming and Lammetization"
      ],
      "metadata": {
        "id": "uYINKqmOXFqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def stemming(text):\n",
        "    obj=PorterStemmer()\n",
        "    stem_word=[obj.stem(word) for word in text.split()]\n",
        "    return stem_word"
      ],
      "metadata": {
        "id": "m9JjbjUMXACR"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = \"The quick brown foxes are jumping over the lazy dogs\""
      ],
      "metadata": {
        "id": "lTe--fNIXHl9"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming(input_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cro48ZoaYjw_",
        "outputId": "6146a1d3-488c-447b-8408-32c20a022b22"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'quick', 'brown', 'fox', 'are', 'jump', 'over', 'the', 'lazi', 'dog']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Lammetization\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8zff5WjZQFI",
        "outputId": "663f2417-4b01-489c-ae68-5fdc2c92aab8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def lammatization(text):\n",
        "    words=text.split()\n",
        "    lemmetizer=WordNetLemmatizer()\n",
        "    lemetized_word=[lemmetizer.lemmatize(word) for word in words]\n",
        "    return lemetized_word"
      ],
      "metadata": {
        "id": "MFxngWyzZZvO"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lammatization(input_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdri0SHEZft4",
        "outputId": "74fe8747-d4cd-4c17-d87a-8333604cabd0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'quick',\n",
              " 'brown',\n",
              " 'fox',\n",
              " 'are',\n",
              " 'jumping',\n",
              " 'over',\n",
              " 'the',\n",
              " 'lazy',\n",
              " 'dog']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a different senerio and work accoring to that\n",
        "- tokenization\n",
        "- lowercase\n",
        "- uppercase\n",
        "- emojis\n",
        "- pancuations\n",
        "- html,url\n",
        "- stopwords\n",
        "- abbravation or slang\n",
        "- steemming and lemmetization\n",
        "- spelling correction\n",
        "\n",
        "did you get the idea how the clean the text\n"
      ],
      "metadata": {
        "id": "DIAzoQSDZ5I2"
      }
    }
  ]
}